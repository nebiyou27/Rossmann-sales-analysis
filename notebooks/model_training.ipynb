{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "\n",
    "# Configure inline plots for Jupyter Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neba\\AppData\\Local\\Temp\\ipykernel_10640\\2208503396.py:27: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(os.path.join(base_path, \"train.csv\"))\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Set base path for data\n",
    "base_path = r\"C:\\Users\\neba\\Downloads\\Compressed\\rossmann-store-sales\"\n",
    "\n",
    "# Create necessary directories\n",
    "log_dir = \"logs\"\n",
    "model_dir = \"models\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=os.path.join(log_dir, \"model_training.log\"),\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "logger.info(\"Logging setup complete for model training.\")\n",
    "\n",
    "try:\n",
    "    # Load datasets\n",
    "    logger.info(\"Loading datasets.\")\n",
    "    train_df = pd.read_csv(os.path.join(base_path, \"train.csv\"))\n",
    "    test_df = pd.read_csv(os.path.join(base_path, \"test.csv\"))\n",
    "    store_df = pd.read_csv(os.path.join(base_path, \"store.csv\"))\n",
    "    logger.info(\"Datasets loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred while loading the datasets: {e}\", exc_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Summary\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   Store          1017209 non-null  int64         \n",
      " 1   DayOfWeek      1017209 non-null  int64         \n",
      " 2   Date           1017209 non-null  datetime64[ns]\n",
      " 3   Sales          1017209 non-null  int64         \n",
      " 4   Customers      1017209 non-null  int64         \n",
      " 5   Open           1017209 non-null  int64         \n",
      " 6   Promo          1017209 non-null  int64         \n",
      " 7   StateHoliday   1017209 non-null  object        \n",
      " 8   SchoolHoliday  1017209 non-null  int64         \n",
      " 9   Year           1017209 non-null  int32         \n",
      " 10  Month          1017209 non-null  int32         \n",
      " 11  Week           1017209 non-null  UInt32        \n",
      " 12  Day            1017209 non-null  int32         \n",
      "dtypes: UInt32(1), datetime64[ns](1), int32(3), int64(7), object(1)\n",
      "memory usage: 86.3+ MB\n",
      "None\n",
      "               Store     DayOfWeek                           Date  \\\n",
      "count   1.017209e+06  1.017209e+06                        1017209   \n",
      "unique           NaN           NaN                            NaN   \n",
      "top              NaN           NaN                            NaN   \n",
      "freq             NaN           NaN                            NaN   \n",
      "mean    5.584297e+02  3.998341e+00  2014-04-11 01:30:42.846061824   \n",
      "min     1.000000e+00  1.000000e+00            2013-01-01 00:00:00   \n",
      "25%     2.800000e+02  2.000000e+00            2013-08-17 00:00:00   \n",
      "50%     5.580000e+02  4.000000e+00            2014-04-02 00:00:00   \n",
      "75%     8.380000e+02  6.000000e+00            2014-12-12 00:00:00   \n",
      "max     1.115000e+03  7.000000e+00            2015-07-31 00:00:00   \n",
      "std     3.219087e+02  1.997391e+00                            NaN   \n",
      "\n",
      "               Sales     Customers          Open         Promo StateHoliday  \\\n",
      "count   1.017209e+06  1.017209e+06  1.017209e+06  1.017209e+06      1017209   \n",
      "unique           NaN           NaN           NaN           NaN            5   \n",
      "top              NaN           NaN           NaN           NaN            0   \n",
      "freq             NaN           NaN           NaN           NaN       855087   \n",
      "mean    5.773819e+03  6.331459e+02  8.301067e-01  3.815145e-01          NaN   \n",
      "min     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00          NaN   \n",
      "25%     3.727000e+03  4.050000e+02  1.000000e+00  0.000000e+00          NaN   \n",
      "50%     5.744000e+03  6.090000e+02  1.000000e+00  0.000000e+00          NaN   \n",
      "75%     7.856000e+03  8.370000e+02  1.000000e+00  1.000000e+00          NaN   \n",
      "max     4.155100e+04  7.388000e+03  1.000000e+00  1.000000e+00          NaN   \n",
      "std     3.849926e+03  4.644117e+02  3.755392e-01  4.857586e-01          NaN   \n",
      "\n",
      "        SchoolHoliday          Year         Month       Week           Day  \n",
      "count    1.017209e+06  1.017209e+06  1.017209e+06  1017209.0  1.017209e+06  \n",
      "unique            NaN           NaN           NaN       <NA>           NaN  \n",
      "top               NaN           NaN           NaN       <NA>           NaN  \n",
      "freq              NaN           NaN           NaN       <NA>           NaN  \n",
      "mean     1.786467e-01  2.013832e+03  5.846762e+00  23.615515  1.570279e+01  \n",
      "min      0.000000e+00  2.013000e+03  1.000000e+00        1.0  1.000000e+00  \n",
      "25%      0.000000e+00  2.013000e+03  3.000000e+00       11.0  8.000000e+00  \n",
      "50%      0.000000e+00  2.014000e+03  6.000000e+00       22.0  1.600000e+01  \n",
      "75%      0.000000e+00  2.014000e+03  8.000000e+00       35.0  2.300000e+01  \n",
      "max      1.000000e+00  2.015000e+03  1.200000e+01       52.0  3.100000e+01  \n",
      "std      3.830564e-01  7.773960e-01  3.326097e+00  14.433381  8.787638e+00  \n",
      "\n",
      "Store Dataset Summary\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1115 entries, 0 to 1114\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Store                      1115 non-null   int64  \n",
      " 1   StoreType                  1115 non-null   object \n",
      " 2   Assortment                 1115 non-null   object \n",
      " 3   CompetitionDistance        1115 non-null   float64\n",
      " 4   CompetitionOpenSinceMonth  1115 non-null   float64\n",
      " 5   CompetitionOpenSinceYear   1115 non-null   float64\n",
      " 6   Promo2                     1115 non-null   int64  \n",
      " 7   Promo2SinceWeek            1115 non-null   float64\n",
      " 8   Promo2SinceYear            1115 non-null   float64\n",
      " 9   PromoInterval              1115 non-null   object \n",
      " 10  Promo_Jan                  1115 non-null   int64  \n",
      " 11  Promo_Feb                  1115 non-null   int64  \n",
      " 12  Promo_Mar                  1115 non-null   int64  \n",
      " 13  Promo_Apr                  1115 non-null   int64  \n",
      " 14  Promo_May                  1115 non-null   int64  \n",
      " 15  Promo_Jun                  1115 non-null   int64  \n",
      " 16  Promo_Jul                  1115 non-null   int64  \n",
      " 17  Promo_Aug                  1115 non-null   int64  \n",
      " 18  Promo_Sep                  1115 non-null   int64  \n",
      " 19  Promo_Oct                  1115 non-null   int64  \n",
      " 20  Promo_Nov                  1115 non-null   int64  \n",
      " 21  Promo_Dec                  1115 non-null   int64  \n",
      "dtypes: float64(5), int64(14), object(3)\n",
      "memory usage: 191.8+ KB\n",
      "None\n",
      "             Store StoreType Assortment  CompetitionDistance  \\\n",
      "count   1115.00000      1115       1115          1115.000000   \n",
      "unique         NaN         4          3                  NaN   \n",
      "top            NaN         a          a                  NaN   \n",
      "freq           NaN       602        593                  NaN   \n",
      "mean     558.00000       NaN        NaN          5390.356054   \n",
      "std      322.01708       NaN        NaN          7657.975601   \n",
      "min        1.00000       NaN        NaN            -1.000000   \n",
      "25%      279.50000       NaN        NaN           710.000000   \n",
      "50%      558.00000       NaN        NaN          2320.000000   \n",
      "75%      836.50000       NaN        NaN          6875.000000   \n",
      "max     1115.00000       NaN        NaN         75860.000000   \n",
      "\n",
      "        CompetitionOpenSinceMonth  CompetitionOpenSinceYear       Promo2  \\\n",
      "count                 1115.000000               1115.000000  1115.000000   \n",
      "unique                        NaN                       NaN          NaN   \n",
      "top                           NaN                       NaN          NaN   \n",
      "freq                          NaN                       NaN          NaN   \n",
      "mean                     4.930942               1370.939013     0.512108   \n",
      "std                      4.284924                935.467654     0.500078   \n",
      "min                      0.000000                  0.000000     0.000000   \n",
      "25%                      0.000000                  0.000000     0.000000   \n",
      "50%                      4.000000               2006.000000     1.000000   \n",
      "75%                      9.000000               2011.000000     1.000000   \n",
      "max                     12.000000               2015.000000     1.000000   \n",
      "\n",
      "        Promo2SinceWeek  Promo2SinceYear PromoInterval  ...    Promo_Mar  \\\n",
      "count       1115.000000      1115.000000          1115  ...  1115.000000   \n",
      "unique              NaN              NaN             4  ...          NaN   \n",
      "top                 NaN              NaN          None  ...          NaN   \n",
      "freq                NaN              NaN           544  ...          NaN   \n",
      "mean          12.083408      1030.239462           NaN  ...     0.095067   \n",
      "std           15.542241      1006.038782           NaN  ...     0.293439   \n",
      "min            0.000000         0.000000           NaN  ...     0.000000   \n",
      "25%            0.000000         0.000000           NaN  ...     0.000000   \n",
      "50%            1.000000      2009.000000           NaN  ...     0.000000   \n",
      "75%           22.000000      2012.000000           NaN  ...     0.000000   \n",
      "max           50.000000      2015.000000           NaN  ...     1.000000   \n",
      "\n",
      "          Promo_Apr    Promo_May    Promo_Jun    Promo_Jul    Promo_Aug  \\\n",
      "count   1115.000000  1115.000000  1115.000000  1115.000000  1115.000000   \n",
      "unique          NaN          NaN          NaN          NaN          NaN   \n",
      "top             NaN          NaN          NaN          NaN          NaN   \n",
      "freq            NaN          NaN          NaN          NaN          NaN   \n",
      "mean       0.300448     0.116592     0.095067     0.300448     0.116592   \n",
      "std        0.458659     0.321077     0.293439     0.458659     0.321077   \n",
      "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%        1.000000     0.000000     0.000000     1.000000     0.000000   \n",
      "max        1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "          Promo_Sep    Promo_Oct    Promo_Nov    Promo_Dec  \n",
      "count   1115.000000  1115.000000  1115.000000  1115.000000  \n",
      "unique          NaN          NaN          NaN          NaN  \n",
      "top             NaN          NaN          NaN          NaN  \n",
      "freq            NaN          NaN          NaN          NaN  \n",
      "mean       0.095067     0.300448     0.116592     0.095067  \n",
      "std        0.293439     0.458659     0.321077     0.293439  \n",
      "min        0.000000     0.000000     0.000000     0.000000  \n",
      "25%        0.000000     0.000000     0.000000     0.000000  \n",
      "50%        0.000000     0.000000     0.000000     0.000000  \n",
      "75%        0.000000     1.000000     0.000000     0.000000  \n",
      "max        1.000000     1.000000     1.000000     1.000000  \n",
      "\n",
      "[11 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Summarize train dataset\n",
    "print(\"Train Dataset Summary\")\n",
    "print(train_df.info())  # Overview of columns, data types, and non-null counts\n",
    "print(train_df.describe(include='all'))  # Summary statistics for numeric and non-numeric columns\n",
    "\n",
    "# Summarize store dataset\n",
    "print(\"\\nStore Dataset Summary\")\n",
    "print(store_df.info())\n",
    "print(store_df.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in Train Dataset\n",
      "Store            0\n",
      "DayOfWeek        0\n",
      "Date             0\n",
      "Sales            0\n",
      "Customers        0\n",
      "Open             0\n",
      "Promo            0\n",
      "StateHoliday     0\n",
      "SchoolHoliday    0\n",
      "Year             0\n",
      "Month            0\n",
      "Week             0\n",
      "Day              0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Store Dataset\n",
      "Store                        0\n",
      "StoreType                    0\n",
      "Assortment                   0\n",
      "CompetitionDistance          0\n",
      "CompetitionOpenSinceMonth    0\n",
      "CompetitionOpenSinceYear     0\n",
      "Promo2                       0\n",
      "Promo2SinceWeek              0\n",
      "Promo2SinceYear              0\n",
      "PromoInterval                0\n",
      "Promo_Jan                    0\n",
      "Promo_Feb                    0\n",
      "Promo_Mar                    0\n",
      "Promo_Apr                    0\n",
      "Promo_May                    0\n",
      "Promo_Jun                    0\n",
      "Promo_Jul                    0\n",
      "Promo_Aug                    0\n",
      "Promo_Sep                    0\n",
      "Promo_Oct                    0\n",
      "Promo_Nov                    0\n",
      "Promo_Dec                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Missing values in train dataset\n",
    "print(\"Missing Values in Train Dataset\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# Missing values in store dataset\n",
    "print(\"\\nMissing Values in Store Dataset\")\n",
    "print(store_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Types and Unique Values\n",
      "Store                     int64\n",
      "DayOfWeek                 int64\n",
      "Date             datetime64[ns]\n",
      "Sales                     int64\n",
      "Customers                 int64\n",
      "Open                      int64\n",
      "Promo                     int64\n",
      "StateHoliday             object\n",
      "SchoolHoliday             int64\n",
      "Year                      int32\n",
      "Month                     int32\n",
      "Week                     UInt32\n",
      "Day                       int32\n",
      "dtype: object\n",
      "\n",
      "Store Data Types and Unique Values\n",
      "Store                          int64\n",
      "StoreType                     object\n",
      "Assortment                    object\n",
      "CompetitionDistance          float64\n",
      "CompetitionOpenSinceMonth    float64\n",
      "CompetitionOpenSinceYear     float64\n",
      "Promo2                         int64\n",
      "Promo2SinceWeek              float64\n",
      "Promo2SinceYear              float64\n",
      "PromoInterval                 object\n",
      "Promo_Jan                      int64\n",
      "Promo_Feb                      int64\n",
      "Promo_Mar                      int64\n",
      "Promo_Apr                      int64\n",
      "Promo_May                      int64\n",
      "Promo_Jun                      int64\n",
      "Promo_Jul                      int64\n",
      "Promo_Aug                      int64\n",
      "Promo_Sep                      int64\n",
      "Promo_Oct                      int64\n",
      "Promo_Nov                      int64\n",
      "Promo_Dec                      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types and unique values\n",
    "print(\"Train Data Types and Unique Values\")\n",
    "print(train_df.dtypes)\n",
    "print(\"\\nStore Data Types and Unique Values\")\n",
    "print(store_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for StateHoliday in train dataset:\n",
      "StateHoliday\n",
      "0    855087\n",
      "0    131072\n",
      "a     20260\n",
      "b      6690\n",
      "c      4100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for StoreType in store dataset:\n",
      "StoreType\n",
      "a    602\n",
      "d    348\n",
      "c    148\n",
      "b     17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Assortment in store dataset:\n",
      "Assortment\n",
      "a    593\n",
      "c    513\n",
      "b      9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for PromoInterval in store dataset:\n",
      "PromoInterval\n",
      "None                544\n",
      "Jan,Apr,Jul,Oct     335\n",
      "Feb,May,Aug,Nov     130\n",
      "Mar,Jun,Sept,Dec    106\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check value counts for categorical columns in train dataset\n",
    "categorical_columns_train = train_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns_train:\n",
    "    print(f\"Value counts for {col} in train dataset:\")\n",
    "    print(train_df[col].value_counts())\n",
    "    print()\n",
    "\n",
    "# Check value counts for categorical columns in store dataset\n",
    "categorical_columns_store = store_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns_store:\n",
    "    print(f\"Value counts for {col} in store dataset:\")\n",
    "    print(store_df[col].value_counts())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the StateHoliday column contains mixed data types (both strings and integers). To fix this, you need to standardize the column to have a uniform data type (e.g., convert everything to strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values in 'StateHoliday' to strings\n",
    "train_df['StateHoliday'] = train_df['StateHoliday'].astype(str)\n",
    "\n",
    "# Apply LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['StateHoliday'] = label_encoder.fit_transform(train_df['StateHoliday'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encode Categorical Features\n",
    "One-hot encode categorical columns like StoreType, Assortment, and PromoInterval in store_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df = pd.get_dummies(store_df, columns=['StoreType', 'Assortment', 'PromoInterval'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date features in train_df\n",
    "train_df['Year'] = train_df['Date'].dt.year\n",
    "train_df['Month'] = train_df['Date'].dt.month\n",
    "train_df['Week'] = train_df['Date'].dt.isocalendar().week\n",
    "train_df['Day'] = train_df['Date'].dt.day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale numerical features in train_df\n",
    "num_features_train = ['Sales', 'Customers']\n",
    "train_df[num_features_train] = scaler.fit_transform(train_df[num_features_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to scale in store_df\n",
    "num_features_store = ['CompetitionDistance']\n",
    "\n",
    "# Apply scaling to store_df\n",
    "store_df[num_features_store] = scaler.fit_transform(store_df[num_features_store])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train_df and store_df\n",
    "merged_df = train_df.merge(store_df, on='Store', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store                             0\n",
      "DayOfWeek                         0\n",
      "Date                              0\n",
      "Sales                             0\n",
      "Customers                         0\n",
      "Open                              0\n",
      "Promo                             0\n",
      "StateHoliday                      0\n",
      "SchoolHoliday                     0\n",
      "Year                              0\n",
      "Month                             0\n",
      "Week                              0\n",
      "Day                               0\n",
      "CompetitionDistance               0\n",
      "CompetitionOpenSinceMonth         0\n",
      "CompetitionOpenSinceYear          0\n",
      "Promo2                            0\n",
      "Promo2SinceWeek                   0\n",
      "Promo2SinceYear                   0\n",
      "Promo_Jan                         0\n",
      "Promo_Feb                         0\n",
      "Promo_Mar                         0\n",
      "Promo_Apr                         0\n",
      "Promo_May                         0\n",
      "Promo_Jun                         0\n",
      "Promo_Jul                         0\n",
      "Promo_Aug                         0\n",
      "Promo_Sep                         0\n",
      "Promo_Oct                         0\n",
      "Promo_Nov                         0\n",
      "Promo_Dec                         0\n",
      "StoreType_b                       0\n",
      "StoreType_c                       0\n",
      "StoreType_d                       0\n",
      "Assortment_b                      0\n",
      "Assortment_c                      0\n",
      "PromoInterval_Jan,Apr,Jul,Oct     0\n",
      "PromoInterval_Mar,Jun,Sept,Dec    0\n",
      "PromoInterval_None                0\n",
      "dtype: int64\n",
      "Store                                      int64\n",
      "DayOfWeek                                  int64\n",
      "Date                              datetime64[ns]\n",
      "Sales                                    float64\n",
      "Customers                                float64\n",
      "Open                                       int64\n",
      "Promo                                      int64\n",
      "StateHoliday                               int64\n",
      "SchoolHoliday                              int64\n",
      "Year                                       int32\n",
      "Month                                      int32\n",
      "Week                                      UInt32\n",
      "Day                                        int32\n",
      "CompetitionDistance                      float64\n",
      "CompetitionOpenSinceMonth                float64\n",
      "CompetitionOpenSinceYear                 float64\n",
      "Promo2                                     int64\n",
      "Promo2SinceWeek                          float64\n",
      "Promo2SinceYear                          float64\n",
      "Promo_Jan                                  int64\n",
      "Promo_Feb                                  int64\n",
      "Promo_Mar                                  int64\n",
      "Promo_Apr                                  int64\n",
      "Promo_May                                  int64\n",
      "Promo_Jun                                  int64\n",
      "Promo_Jul                                  int64\n",
      "Promo_Aug                                  int64\n",
      "Promo_Sep                                  int64\n",
      "Promo_Oct                                  int64\n",
      "Promo_Nov                                  int64\n",
      "Promo_Dec                                  int64\n",
      "StoreType_b                                 bool\n",
      "StoreType_c                                 bool\n",
      "StoreType_d                                 bool\n",
      "Assortment_b                                bool\n",
      "Assortment_c                                bool\n",
      "PromoInterval_Jan,Apr,Jul,Oct               bool\n",
      "PromoInterval_Mar,Jun,Sept,Dec              bool\n",
      "PromoInterval_None                          bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(merged_df.isnull().sum())\n",
    "\n",
    "# Validate data types\n",
    "print(merged_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Observations\n",
    "No Missing Values:\n",
    "\n",
    "All columns have 0 missing values, meaning the data is clean and ready for modeling.\n",
    "Data Types:\n",
    "\n",
    "Numeric columns like Sales, Customers, and CompetitionDistance are correctly set as float64 or int64.\n",
    "Categorical columns like StateHoliday have been encoded as int64.\n",
    "Boolean columns (e.g., StoreType_b, PromoInterval_Jan,Apr,Jul,Oct) are appropriately bool.\n",
    "Date Column:\n",
    "\n",
    "The Date column is correctly stored as datetime64[ns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering\n",
    "New Features to Add\n",
    "IsWeekend: Whether the day is a weekend (Saturday or Sunday).\n",
    "Quarter: The quarter of the year (1, 2, 3, or 4).\n",
    "IsHolidaySeason: Whether the date falls in a holiday season (November or December)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['IsWeekend'] = merged_df['DayOfWeek'].isin([6, 7]).astype(int)\n",
    "merged_df['Quarter'] = merged_df['Month'].apply(lambda x: (x - 1) // 3 + 1)\n",
    "merged_df['IsHolidaySeason'] = merged_df['Month'].isin([11, 12]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target\n",
    "X = merged_df.drop(columns=['Sales', 'Date'])\n",
    "y = merged_df['Sales']\n",
    "\n",
    "# Train-test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf_pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test, y_pred)\n\u001b[0;32m     19\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\neba\\Desktop\\Rossmann-sales-analysis\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:194\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_sig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m params\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\inspect.py:3259\u001b[0m, in \u001b[0;36mSignature.bind\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[0;32m   3256\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[0;32m   3257\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[0;32m   3258\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\inspect.py:3248\u001b[0m, in \u001b[0;36mSignature._bind\u001b[1;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[0;32m   3246\u001b[0m         arguments[kwargs_param\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[0;32m   3247\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3249\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   3250\u001b[0m                 arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[0;32m   3252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[1;31mTypeError\u001b[0m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define the pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('model', RandomForestRegressor(random_state=42, n_estimators=100))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Random Forest Regressor Performance:\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R² Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Performance:\n",
      "RMSE: 0.11456543194228826\n",
      "MAE: 0.06851764958761702\n",
      "R² Score: 0.9868453666768269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)  # MSE\n",
    "rmse = np.sqrt(mse)  # RMSE\n",
    "mae = mean_absolute_error(y_test, y_pred)  # MAE\n",
    "r2 = r2_score(y_test, y_pred)  # R²\n",
    "\n",
    "print(f\"Random Forest Regressor Performance:\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R² Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lagged sales as features\n",
    "for lag in range(1, 7):  # Lags for the past 6 weeks\n",
    "    merged_df[f'Lag_{lag}'] = merged_df['Sales'].shift(lag * 7)\n",
    "\n",
    "# Drop rows with NaN (due to lagging)\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "# Re-split the data\n",
    "X = merged_df.drop(columns=['Sales', 'Date'])\n",
    "y = merged_df['Sales']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': RandomForestRegressor(random_state=42)}\n"
     ]
    }
   ],
   "source": [
    "# Print the names of the pipeline steps\n",
    "print(rf_pipeline.named_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the feature importances\n",
    "feature_importance = rf_pipeline.named_steps['model'].feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': RandomForestRegressor(random_state=42)}\n"
     ]
    }
   ],
   "source": [
    "print(rf_pipeline.named_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Example preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['numeric_column1', 'numeric_column2']),\n",
    "        ('cat', OneHotEncoder(), ['categorical_column'])\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
